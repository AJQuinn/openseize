{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "684d8714",
   "metadata": {},
   "source": [
    "# File Reading "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8719f7d",
   "metadata": {},
   "source": [
    "- [**Imports**](#Imports)\n",
    "- [**Introduction**](#Introduction)\n",
    "- [**Reading EDF Files**](#Reading-EDF-Files)\n",
    "    - [**Properties and Attributes**](#Properties-and-Attributes)\n",
    "    - [**Header Information**](#Header-Information)\n",
    "    - [**Reading EDF Data to Arrays**](#Reading-EDF-Data-to-Arrays)\n",
    "    - [**File Resources and Context Management**](#File-Resources-and-Context-Management)\n",
    "- [**Writing EDF Files**](#Writing-EDF-Files)\n",
    "- [**EDF Annotations**](#EDF-Annotations)\n",
    "- [**Producing from EDF Files with Annotations**](#Producing-from-EDF-Files-with-Annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a918b7",
   "metadata": {},
   "source": [
    "## Objectives for 7/7 - 7-14\n",
    "\n",
    "- 1. <s>Review producers demo checking for typos, markdown errors, and hyperlink errors.</s>\n",
    "- 2. Review differences between our producer demos. A few items I noticed:\n",
    "    - a. Code simplicity -- my largest cell contains only 8 lines. Demos should use only small code snippets.\n",
    "    - b. Show call signatures and help documentation\n",
    "    - c. Highlight important points with text boldings, colors etc.\n",
    "    - d. print what instances look like on return where needed\n",
    "    - e. limit use of subfunctions with kwargs set to specific values; delegate kwargs to caller function (65)\n",
    "    - f. realistic examples -see the sizes of arrays chosen, the selection of items to mask in producers etc.\n",
    "- 3. This file reading demo\n",
    "\n",
    "Todo:\n",
    "- finish first draft\n",
    "- colorize everything\n",
    "- <s>fix hyperlinks</s>\n",
    "- proof\n",
    "- push clean notebook that demonstrates downloading of files from repo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d5c4bf",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bab17e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from openseize.io.bases import Reader, Header, Writer\n",
    "from openseize.io import edf, annotations\n",
    "from openseize import demos\n",
    "from openseize import producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2d6827",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e404c3f3",
   "metadata": {},
   "source": [
    "><s><font size=3> Openseize provides a host of tools for working with and analyzing EEG data. This data can be stored in various file types, and a critical step to performing any work on the data within a file is to read that data into memory. The openseize package provides <font color='darkcyan'><b>an EDF Reader class that can take raw EDF files and extract the EEG records from them for analysis.</b></font> \n",
    ">\n",
    "><s><font size=3> If you would like to work with additional file types that support EEG data, we describe the requirements for creating your own Readers towards the end of this demo.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5a9e71",
   "metadata": {},
   "source": [
    "><font color='red'><font size=3>Openseize currently provides tools for reading and writing European Data Format (EDF) binary files. The details of this file specification can be found here: https://www.edfplus.info/specs/edf.html</font>\n",
    ">\n",
    "><font color='red'><font size=3>This demo will describe how to open, read, and produce data from an EDF file using the <font color='darkcyan'><b>EDF Reader class</b></font> and write data to an EDF file using the <font color='darkcyan'><b>EDF Writer class</b></font>. Additionally, this demo will cover how to read Comma Separated (CSV) and Tab separated value (TSV) annotation text files and use the resulting annotations to mask produced EEG numpy arrays.</font>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a718b1f2",
   "metadata": {},
   "source": [
    "## Reading EDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c25f5f2",
   "metadata": {},
   "source": [
    "<font color='red'> I think it is better to reverse the order and show the help call to the edf.Reader. This will show that the class needs to be initialized with a path that you will then get.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae001c",
   "metadata": {},
   "source": [
    "><font size=3> In order to read from a file, we first need to acquire the path to the file on your machine. For these demos, we have stored demo data to a remote Zenodo repository. The demos module we imported has access to the files in this repo; we can see what's available by calling the <font color='firebrick'><i>available</i></font> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29c59cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Available demo data files & location---\n",
      "------------------------------------------\n",
      "annotations_001.txt            '/home/matt/python...nnotations_001.txt'\n",
      "recording_001.edf              '/home/matt/python.../recording_001.edf'\n",
      "5872_Left_group A.txt          '/home/matt/python...2_Left_group A.txt'\n",
      "CW0259_SWDs.npy                '/home/matt/python...ta/CW0259_SWDs.npy'\n",
      "subset_001.edf                 '/home/matt/python...ata/subset_001.edf'\n",
      "5872_Left_group A.edf          '/home/matt/python...2_Left_group A.edf'\n"
     ]
    }
   ],
   "source": [
    "demos.paths.available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a026c1",
   "metadata": {},
   "source": [
    "><font size=3> If the file is currently on your system, you'll see a local location after that file's name. If not, you'll see a link to the Zenodo repo. Regardless of its location, we can get access to a file by calling the <font color='firebrick'><i>locate</i></font> method. If the file hasn't already been found on your local machine, it will be downloaded to the demos data folder. This may take a few minutes, but will occur only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76597988",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get access to the file's path locally, downloading if needed\n",
    "filepath = demos.paths.locate('recording_001.edf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a364bc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Available demo data files & location---\n",
      "------------------------------------------\n",
      "annotations_001.txt            '/home/matt/python...nnotations_001.txt'\n",
      "recording_001.edf              '/home/matt/python.../recording_001.edf'\n",
      "5872_Left_group A.txt          '/home/matt/python...2_Left_group A.txt'\n",
      "CW0259_SWDs.npy                '/home/matt/python...ta/CW0259_SWDs.npy'\n",
      "subset_001.edf                 '/home/matt/python...ata/subset_001.edf'\n",
      "5872_Left_group A.edf          '/home/matt/python...2_Left_group A.edf'\n"
     ]
    }
   ],
   "source": [
    "# We can see the file's location on our local machine now that it has downloaded.\n",
    "demos.paths.available"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048d682b",
   "metadata": {},
   "source": [
    "><font size=3>Now that we have access to a filepath, we can build a Reader around it. Before we do so, however, <font color=firebrick><i>let's take a look at its built-in help file.</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27e09623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Reader in module openseize.io.edf:\n",
      "\n",
      "class Reader(openseize.io.bases.Reader)\n",
      " |  Reader(path)\n",
      " |  \n",
      " |  A reader of European Data Format (EDF/EDF+) files.\n",
      " |  \n",
      " |  The EDF specification has a header section followed by data records\n",
      " |  Each data record contains all signals stored sequentially. EDF+\n",
      " |  files include an annotation signal within each data record. To\n",
      " |  distinguish these signals we refer to data containing signals as\n",
      " |  channels and annotation signals as annotation. Currently, this reader\n",
      " |  does not support the reading of annotation signals.\n",
      " |  \n",
      " |  For details on the EDF/+ file specification please see:\n",
      " |  \n",
      " |  https://www.edfplus.info/specs/index.html\n",
      " |  \n",
      " |  Attributes:\n",
      " |      header: A dictionary representation of an EDF Header.\n",
      " |      shape: A tuple of channels, samples contained in this EDF\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Reader\n",
      " |      openseize.io.bases.Reader\n",
      " |      abc.ABC\n",
      " |      openseize.core.mixins.ViewInstance\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path)\n",
      " |      Extends the Reader ABC with a header attribute.\n",
      " |  \n",
      " |  read(self, start, stop=None, channels=None, padvalue=nan)\n",
      " |      Reads samples from this EDF for the specified channels.\n",
      " |      \n",
      " |      Args:\n",
      " |          start: int\n",
      " |              The start sample index to read.\n",
      " |          stop: int\n",
      " |              The stop sample index to read (exclusive). If None, samples\n",
      " |              will be read until the end of file. Default is None.\n",
      " |          channels: sequence\n",
      " |              Sequence of channels to read from EDF. If None, all channels\n",
      " |              in the EDF will be read. Default is None.\n",
      " |          padvalue: float\n",
      " |              Value to pad to channels that run out of samples to return.\n",
      " |              Only applicable if sample rates of channels differ. Default\n",
      " |              padvalue is NaN.\n",
      " |      \n",
      " |      Returns: \n",
      " |          A float64 array of shape len(chs) x (stop-start) samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  shape\n",
      " |      Returns a 2-tuple containing the number of channels and \n",
      " |      number of samples in this EDF.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.io.bases.Reader:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Return reader instance as target variable of this context.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |      On context exit, close this reader's file object and propogate\n",
      " |      errors by returning None.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close this reader instance's opened file object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openseize.io.bases.Reader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.core.mixins.ViewInstance:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns the __init__'s signature as the echo representation.\n",
      " |      \n",
      " |      Returns: str\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns this instances print representation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(edf.Reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc20745",
   "metadata": {},
   "source": [
    "><font size=3>As we can see, <b>the EDF Reader takes in a single parameter, the file path we obtained earlier</b>. <font color=firebrick><i>Let's pass in that path to create our Reader object.</i></font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c714a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = edf.Reader(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad81790",
   "metadata": {},
   "source": [
    "### Properties and Attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7160acaa",
   "metadata": {},
   "source": [
    "><font size=3><s>Now that we have a Reader, we can do a printout to look at the attributes it provides us with.</s>\n",
    "    \n",
    "<font color='red'>To view the attributes and properties of this reader we can print the reader instance.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76b33d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Object\n",
      "---Attributes & Properties---\n",
      "{'path': PosixPath('/home/matt/python/nri/openseize/demos/data/recording_001.edf'),\n",
      " 'header': {'version': '0',\n",
      "            'patient': 'PIN-42 M 11-MAR-1952 Animal',\n",
      "            'recording': 'Startdate 15-AUG-2020 X X X',\n",
      "            'start_date': '15.08.20',\n",
      "            'start_time': '09.59.15',\n",
      "            'header_bytes': 1536,\n",
      "            'reserved_0': 'EDF+C',\n",
      "            'num_records': 3775,\n",
      "            'record_duration': 1.0,\n",
      "            'num_signals': 5,\n",
      "            'names': ['EEG EEG_1_SA-B', 'EEG EEG_2_SA-B', 'EEG EEG_3_SA-B',\n",
      "                      'EEG EEG_4_SA-B', 'EDF Annotations'],\n",
      "            'transducers': ['8401 HS:15279', '8401 HS:15279', '8401 HS:15279',\n",
      "                            '8401 HS:15279', ''],\n",
      "            'physical_dim': ['uV', 'uV', 'uV', 'uV', ''],\n",
      "            'physical_min': [-8144.31, -8144.31, -8144.31, -8144.31, -1.0],\n",
      "            'physical_max': [8144.319, 8144.319, 8144.319, 8144.319, 1.0],\n",
      "            'digital_min': [-8192.0, -8192.0, -8192.0, -8192.0, -32768.0],\n",
      "            'digital_max': [8192.0, 8192.0, 8192.0, 8192.0, 32767.0],\n",
      "            'prefiltering': ['none', 'none', 'none', 'none', ''],\n",
      "            'samples_per_record': [5000, 5000, 5000, 5000, 1024],\n",
      "            'reserved_1': ['', '', '', '', '']},\n",
      " 'shape': (4, 18875000)}\n",
      "\n",
      "Type help(Reader) for full documentation\n"
     ]
    }
   ],
   "source": [
    "# Print out the reader object to see its attributes\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be0e595",
   "metadata": {},
   "source": [
    "><s><font size=3>As we can see, the Reader contains <b>three attributes:</b> the <font color=firebrick>path</font> to the file we are reading from, a <font color=firebrick>header</font> dictionary which contains a series of settings and information particular to this EEG reading, and the <font color=firebrick>shape</font> of the data in the Reader.</s> \n",
    ">\n",
    "><s><font size=3>Now that's a lot of prelude. Let's get to the reason we're here: Reading data from a file.</s>\n",
    ">\n",
    "><font size=3><s>Reading is as simple as making a call to the <font color=firebrick>read</font> method on the reader; sensibly, it's the only method required to make a reader a Reader! <font color=firebrick><i>Let's take a closer look at it.</i></font></s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f80bdb",
   "metadata": {},
   "source": [
    "<font color='red'> The reader contains three attributes; a path to the open file, a dictionary containing the EDF's header information, and the shape of the data, represented as a 2-D numpy array, with channels along 0th axis and samples along the 1st axis.</br>\n",
    "The header dictionary contains all information stored to the header section of the EDF file. Details on the exact meaning of each of these fields can be found here: https://www.edfplus.info/specs/edf.html. To ease access to the header data, the header is a dict instance that has been extended to include '.' dot notation attribute access \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "154a9057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EEG EEG_1_SA-B', 'EEG EEG_2_SA-B', 'EEG EEG_3_SA-B', 'EEG EEG_4_SA-B', 'EDF Annotations']\n"
     ]
    }
   ],
   "source": [
    "# Fetch the names of the channels using '.' dot notation\n",
    "print(reader.header.names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6481545",
   "metadata": {},
   "source": [
    "<font color='red'>With the open reader instance, we can call the read method to read EDF data. To understand the parameters of this method lets ask for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55dd090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method read in module openseize.io.edf:\n",
      "\n",
      "read(start, stop=None, channels=None, padvalue=nan) method of openseize.io.edf.Reader instance\n",
      "    Reads samples from this EDF for the specified channels.\n",
      "    \n",
      "    Args:\n",
      "        start: int\n",
      "            The start sample index to read.\n",
      "        stop: int\n",
      "            The stop sample index to read (exclusive). If None, samples\n",
      "            will be read until the end of file. Default is None.\n",
      "        channels: sequence\n",
      "            Sequence of channels to read from EDF. If None, all channels\n",
      "            in the EDF will be read. Default is None.\n",
      "        padvalue: float\n",
      "            Value to pad to channels that run out of samples to return.\n",
      "            Only applicable if sample rates of channels differ. Default\n",
      "            padvalue is NaN.\n",
      "    \n",
      "    Returns: \n",
      "        A float64 array of shape len(chs) x (stop-start) samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(reader.read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7399f9",
   "metadata": {},
   "source": [
    "><s><font size=3>Read takes in at minimum a <font color=firebrick>start value</font>. This indexes at what line in the file we should start reading out data. If you want, you can also give a <font color=firebrick>stop index</font>; otherwise it will read to the end of the file.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79117b",
   "metadata": {},
   "source": [
    "<font color=red>The Readers read method reads from a start sample to a stop sample within the file. If the stop sample is not given the reader will read to the end of the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64bd10be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-19.87908032,   7.95793213,  19.88808032,  18.89390131,\n",
       "         18.89390131],\n",
       "       [-86.4890744 ,  51.70180884,  63.63195703,  88.48643243,\n",
       "         63.63195703],\n",
       "       [-85.49489539,  44.74255573,  29.82987048,  79.53882129,\n",
       "         52.69598785],\n",
       "       [ 62.63777802,  95.44568555,  77.55046326,  36.7891236 ,\n",
       "        109.36419177]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Important for demos -- state what you are showing\n",
    "# read samples 0 to 5 for all 4 channels\n",
    "reader.read(0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb45d67",
   "metadata": {},
   "source": [
    "><s><font size=3>As you can see, this call read out five values from each channel in the EDF data. If we want, we can also pass in a <font color=firebrick>sequence of channel values</font> to limit ourselves to the ones we care about.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af8fd0d",
   "metadata": {},
   "source": [
    "<font color='red'>In addition to reading specific samples, the read method supports reading only a selection of channels.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a31e9cd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-19.87908032,   7.95793213,  19.88808032,  18.89390131,\n",
       "         18.89390131],\n",
       "       [-85.49489539,  44.74255573,  29.82987048,  79.53882129,\n",
       "         52.69598785]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read samples 0 to 5 for channels 0 and 2\n",
    "reader.read(0, 5, channels=[0, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a09e3e",
   "metadata": {},
   "source": [
    "><s><font size=3>Additionally, there is a <font color=firebrick>padvalue parameter</font>, that can be used if your channels do not all have values present at each record. Those empty spaces will be filled with this padvalue.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76323ba",
   "metadata": {},
   "source": [
    "<font color='red'>The EDF file specification allows for signals that may be sampled at different sample rates to be stored to the same file. In this case, a signal will have fewer samples than other signals in the file. In order to return non-ragged numpy arrays, the Reader will append padvalue to shorter signals so that all signals have the same length. This padvalue defaults to np.NaN but may take on any value useful for your analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd9a6c5",
   "metadata": {},
   "source": [
    "<font color='red'>Remove the Header Information section since we have covered the header in enough detail. Bytemaps, count_signals, and filter are internally used and should not need to be called by clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddf439",
   "metadata": {},
   "source": [
    "### <s>Header Information</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d0588b",
   "metadata": {},
   "source": [
    "><s><font size=3>EDF files begin with a few lines of metadata, called a <b>header</b>. This header will contain important details regarding the EDF recording, including information about the patient as well as the recording technology. Generally, though, we will want to keep these lines separate from the actual EEG records.</s>\n",
    ">\n",
    "><s><font size=3>By passing an EDF file into an EDF Reader, <b><i>this information is automatically stored in a Header object</i></b>. There is a general Header abstract base class that the EDF Header implements; we will take a look at this, and how to create Headers of your own, later on. For now, let's look at what the EDF Header provides.</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d21e78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(edf.Header)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b012f2",
   "metadata": {},
   "source": [
    "<s>><font size=3>As we can see, the Header maintains a dictionary of all the information stored in those first few lines that make up the EDF file's header. The Header has a few methods you may find of interest:</s>\n",
    ">    \n",
    "><s><font size=3><ul style=“list-style-type:square”>\n",
    "    <li><font color=firebrick>bytemap</font>, which outputs the list of possible header listings and their associated data types and sizes.</li>\n",
    "    <li><font color=firebrick>count_signals</font>, which tracks the number of signals in the recording (including the implicit annotation channel).</li>\n",
    "    <li><font color=firebrick>filter</font>, which you can use to filter down the information in the header to only those pieces that are relevant to a select number of channels.</li></s>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1949820",
   "metadata": {},
   "outputs": [],
   "source": [
    "#header = reader.header\n",
    "#print(\"Number of signals: {}\".format(header.count_signals()))\n",
    "#print(\"Filtered header by channels 0 and 2: \\n{}\".format(header.filter([0, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ae9798",
   "metadata": {},
   "source": [
    "><s><font size=3>One very nice property of the Header object is that it extends '.' dot notation to access the underlying dictionary elements. <b><i>So we can directly reference attributes of the dictionary without needing to use 'get' methods.</i></b></s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73729449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(\"Patient: {}\".format(header.patient))\\nprint(\"Header Bytes: {}\".format(header.header_bytes))\\nprint(\"Transducers: {}\".format(header.transducers))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"print(\"Patient: {}\".format(header.patient))\n",
    "print(\"Header Bytes: {}\".format(header.header_bytes))\n",
    "print(\"Transducers: {}\".format(header.transducers))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7465f8",
   "metadata": {},
   "source": [
    "### File Resources and Context Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81288a83",
   "metadata": {},
   "source": [
    "<font color='red'>We have seen how to create a Reader instance and use it's read method to extract data from an EDF file. However, the file is still open and using resources that you need to recover. To do this you can call the Reader instance's <font color='firebrick'>close</font> method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a48182",
   "metadata": {},
   "source": [
    "><s><font size=3>The Reader objects we present here are abstractions of Python's base level open and read operations. This being the case, files that we open with Readers will exist in your memory as open links, taking up space. <b>It's very important to close these files when you are done with them.</b> We provide a method on the Reader to do just that.</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5efb255",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1024462",
   "metadata": {},
   "source": [
    "<font color='red'>To address this potential resource leak, openseize supports opening files using context managment. What does this mean?</font>\n",
    "In python you open a text file using a piece of code that looks like this<br>\n",
    "> with open('somefile.text', 'r') as infile:<br>\n",
    "  >> process file\n",
    "    \n",
    "<font color='red'>When opened this way the file is automatically closed at the end of the \"with\" context. EDF Readers support opening EDF files in a context managed protocol too. Here's how to open the file using the context manager protocol.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb3a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.98790803e+01  7.95793213e+00  1.98880803e+01 ...  4.50000000e-03\n",
      "   4.50000000e-03  4.50000000e-03]\n",
      " [-8.64890744e+01  5.17018088e+01  6.36319570e+01 ...  4.50000000e-03\n",
      "   4.50000000e-03  4.50000000e-03]\n",
      " [-8.54948954e+01  4.47425557e+01  2.98298705e+01 ...  4.50000000e-03\n",
      "   4.50000000e-03  4.50000000e-03]\n",
      " [ 6.26377780e+01  9.54456855e+01  7.75504633e+01 ...  4.50000000e-03\n",
      "   4.50000000e-03  4.50000000e-03]]\n",
      "\n",
      "ValueError: seek of closed file\n"
     ]
    }
   ],
   "source": [
    "# Open Reader as Context Manager and read data from within context\n",
    "with edf.Reader(filepath) as reader:\n",
    "    data = reader.read(0)\n",
    "    print(data[:5])\n",
    "\n",
    "# Attempt to read from Reader after context has closed\n",
    "try:\n",
    "    reader.read(0,)\n",
    "except ValueError as err:\n",
    "    print(\"\\nValueError:\", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5629c8",
   "metadata": {},
   "source": [
    "<font color='red'>This method of opening files inside a specific context and performing operations on the data is the preferred way to work with files in Openseize since the resources are automatically recovered at the end of the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8f535",
   "metadata": {},
   "source": [
    "### <s>EDF Context Managers</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b49620a",
   "metadata": {},
   "source": [
    "><s><font size=3>There are some more complex situations where you may want to keep track of your open readers with a Context Manager. This would watch the number of links to that open reader that exist in memory, and automatically close the open file when that number hits zero. This is usually not necessary and often inefficient for small use cases.</s>\n",
    ">    \n",
    "><s><font size=3><b><i>In order to open your Reader as a Context Manager, use the familiar syntax Python uses to open raw files, as seen in the snippet below.</i></b> Note that after the with block has ended, the Reader is considered closed and cannot be read from any more.</s>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e825d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e64e891",
   "metadata": {},
   "source": [
    "## Writing EDF Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7975412",
   "metadata": {},
   "source": [
    "><s><font size=3>While you are most likely only going to need to read from existing EDF files in your posession, openseize also allows you to write your own new EDFs using a <font color=firebrick>Writer</font> object. <b>Here, we will show off the current Writer type available in openseize, the EDF Writer. </b></s>\n",
    ">    \n",
    "<font color='red'>In addition to an EDF file Reader, Openseize provides an EDF file writer. One of the use cases for this Writer is to split an EDF with channels corresponding to multiple subjects into multiple EDFs containing channels for only one subject. For example, if your EDF contains 3 subjects with 4 channels, their is a total of 12 signals in the EDF. The Writer can then be used to write 3 files each containing 4 channels. Lets examine how to use this Writer. We'll again start by asking for help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a00e2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Writer in module openseize.io.edf:\n",
      "\n",
      "class Writer(openseize.io.bases.Writer)\n",
      " |  Writer(path)\n",
      " |  \n",
      " |  A writer of European Data Format (EDF) files.\n",
      " |  \n",
      " |  This writer does not support writing annotations to an EDF file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Writer\n",
      " |      openseize.io.bases.Writer\n",
      " |      abc.ABC\n",
      " |      openseize.core.mixins.ViewInstance\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path)\n",
      " |      Initialize this Writer. See base class for futher details.\n",
      " |  \n",
      " |  write(self, header, data, channels, verbose=True)\n",
      " |      Write header & data for each channel to file object.\n",
      " |      \n",
      " |      Args:\n",
      " |          header: dict\n",
      " |              A mapping of EDF compliant fields and values. For Further\n",
      " |              details see Header class of this module.\n",
      " |          data: 2-D array or Reader instance\n",
      " |              A channels x samples array or Reader instance.\n",
      " |          channels: sequence\n",
      " |              A sequence of channel indices to write to this Writer's \n",
      " |              open file instance.\n",
      " |          verbose: bool\n",
      " |              An option to print progress of write. Default (True) prints\n",
      " |              status update as each record is written.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.io.bases.Writer:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Return instance as target variable of this context.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |      Close this instances file object & propagate any error by \n",
      " |      returning None.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close this instance's opened file object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openseize.io.bases.Writer:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.core.mixins.ViewInstance:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns the __init__'s signature as the echo representation.\n",
      " |      \n",
      " |      Returns: str\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns this instances print representation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(edf.Writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94abee70",
   "metadata": {},
   "source": [
    "><font size=3><s>As we can see, the Writer takes in only a <font color=firebrick>filepath</font> as a constructor input. The only method that is defined is, appropriately, <font color=firebrick>write</font>. As a demonstration, let's write a new EDF file that holds only the first and third channels of the demo EDF we've been working with, along with the appropriate header data. First, <b>let's look at what the write method requires as inputs.</b></s>\n",
    "    \n",
    "<font color='red'>To construct a Writer instance you need to provide a file path where the writer will write the new EDF file to. The <font color=firebrick>write</font> method is what you will need to call in order to write data to the file path. Lets examine this method by asking for the method's documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f1b1a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function write in module openseize.io.edf:\n",
      "\n",
      "write(self, header, data, channels, verbose=True)\n",
      "    Write header & data for each channel to file object.\n",
      "    \n",
      "    Args:\n",
      "        header: dict\n",
      "            A mapping of EDF compliant fields and values. For Further\n",
      "            details see Header class of this module.\n",
      "        data: 2-D array or Reader instance\n",
      "            A channels x samples array or Reader instance.\n",
      "        channels: sequence\n",
      "            A sequence of channel indices to write to this Writer's \n",
      "            open file instance.\n",
      "        verbose: bool\n",
      "            An option to print progress of write. Default (True) prints\n",
      "            status update as each record is written.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(edf.Writer.write)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495a7b0",
   "metadata": {},
   "source": [
    "><s><font size=3>Alright, so it looks like we're going to need <font color=firebrick>the Header object</font> corresponding to our data, <font color=firebrick>the data itself</font> as a 2-D array or just a Reader pointing to the data, and <font color=firebrick>a sequence of channel indices</font> to index our newly stored data. There is also an option to have the writing process print updates as it writes to a file.</s>\n",
    ">\n",
    "><font size=3><s>For now, <b>let's select a filepath for our new file and pass it into a new Writer object.</b></s>\n",
    "    \n",
    "<font color='red'>To write an EDF compliant file, the write method will need an EDF Header instance with all required fields and values expected of the EDF file type. An enumeration of the required fields and values can be found by examining the header printed above or be reading the EDF file specification here: https://www.edfplus.info/specs/edf.html </font>\n",
    "    \n",
    "<font color='red'>In addition to an EDF compliant Header instance, the write method needs data. This data may be an in-memory or a reader instance from which data will be fetched.</font>\n",
    "    \n",
    "<font color='red'>Lastly, the write method can take a list of channel indices. These channel indices will be used to filter both the Header instance and the data. For example if you provide a Header containing metadata for 4 signals and an array containing 4 signals, you can request to write out a subset of the signals, say channel indices [0, 2]. This allows for the splitting of a multichannel EDF into multiple EDFs. Importantly both the new data written and the new Header will contain only data and metadata for the 2 channels written. Lets demonstrate these ideas with an example</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8520078f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writer Object\n",
      "---Attributes & Properties---\n",
      "{'path': PosixPath('/home/matt/python/nri/openseize/demos/data/subset_001.edf')}\n",
      "\n",
      "Type help(Writer) for full documentation\n"
     ]
    }
   ],
   "source": [
    "# Important Demos must work without the client having to change paths within specific cells\n",
    "\n",
    "# Edit this path to a directory on your local machine if you would like to replicate this process.\n",
    "#new_filepath = \"/home/josh/work/openseize/demos/data/recording_001_edited.edf\"\n",
    "\n",
    "save_path = demos.paths.data_dir.joinpath('subset_001.edf')\n",
    "\n",
    "# Create an EDF writer pointing to this path\n",
    "writer = edf.Writer(save_path)\n",
    "print(writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7045d12",
   "metadata": {},
   "source": [
    "><s><font size=3>Now, we note that we are only after the first and third channels of data. One would think you might need to filter the data first, as well as the Header, but the Writer does all that work for us. Just by passing in the values for the channels parameter, <b><i>the Writer will automatically filter the data from the reader as well as the header for those channels.</i></b></s>\n",
    ">\n",
    "><s><font size=3>With that in mind, we can simply pass those respective parameters into the Writer write method to write to our new file.</s>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387e4647",
   "metadata": {},
   "source": [
    "<font color='red'>The writer knows where it will write data to and the write method can now be called to perform the writing. We will write channels 0 and 2 from the 'recording_001.edf' we used earlier. Since this file has a header, we will reuse that header. The write method will select metadata from the header corresponding to channels 0 and 2. The method will also only write data records corresponding to channels 0 and 2. Remember to open the reader as a context manager so the file resources are automatically recovered.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe753466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data: 100.0% complete\r"
     ]
    }
   ],
   "source": [
    "#reader = edf.Reader(filepath) #Re open reader if previously closed\n",
    "#writer.write(reader.header, reader, channels=[0,2]) # Write Reader data from channels 0 and 2 to new EDF file\n",
    "\n",
    "#locate the path to the recording\n",
    "fp = demos.paths.locate('recording_001.edf')\n",
    "\n",
    "#open the reader as context manager\n",
    "with edf.Reader(fp) as reader:\n",
    "    \n",
    "    #open the writer as a context manager\n",
    "    with edf.Writer(save_path) as writer:\n",
    "        \n",
    "        #write channels 0 and 2 from the header and reader's data\n",
    "        writer.write(reader.header, reader, channels=[0,2])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac448af",
   "metadata": {},
   "source": [
    "<font color='red'>Notice here that we called both the Reader and Writer as context managers. Just like reader instances, writer instances maintain an open file to write to that is using your machines resources. By opening both the reader and writer as context managers, these file resources will be closed when the reading and writing is finished.</font>\n",
    "</br>\n",
    "<font color='red'>Now let's reopen the 'subset_001.edf' file we just wrote and make sure the header and data looks correct.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f80284e",
   "metadata": {},
   "source": [
    "><s><font size=3>Did that work like we planned? Let's find out. We'll create a new Reader for the file we just wrote to and take a look at its header and data.</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5232c27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---EDF SUBSET HEADER---\n",
      "{'version': '0',\n",
      " 'patient': 'PIN-42 M 11-MAR-1952 Animal',\n",
      " 'recording': 'Startdate 15-AUG-2020 X X X',\n",
      " 'start_date': '15.08.20',\n",
      " 'start_time': '09.59.15',\n",
      " 'header_bytes': 768,\n",
      " 'reserved_0': 'EDF+C',\n",
      " 'num_records': 3775,\n",
      " 'record_duration': 1.0,\n",
      " 'num_signals': 2,\n",
      " 'names': ['EEG EEG_1_SA-B', 'EEG EEG_3_SA-B'],\n",
      " 'transducers': ['8401 HS:15279', '8401 HS:15279'],\n",
      " 'physical_dim': ['uV', 'uV'],\n",
      " 'physical_min': [-8144.31, -8144.31],\n",
      " 'physical_max': [8144.319, 8144.319],\n",
      " 'digital_min': [-8192.0, -8192.0],\n",
      " 'digital_max': [8192.0, 8192.0],\n",
      " 'prefiltering': ['none', 'none'],\n",
      " 'samples_per_record': [5000, 5000],\n",
      " 'reserved_1': ['', '']}\n",
      "\n",
      "{'Accessible Properties': ['annotated', 'annotation', 'channels', 'offsets',\n",
      "                           'record_map', 'samples', 'slopes']}\n",
      "---EDF SUBSET DATA---\n",
      "[[-19.87908032   7.95793213  19.88808032  18.89390131  18.89390131]\n",
      " [-85.49489539  44.74255573  29.82987048  79.53882129  52.69598785]]\n"
     ]
    }
   ],
   "source": [
    "#second_file_reader = edf.Reader(new_filepath)\n",
    "#print(second_file_reader.header)\n",
    "with edf.Reader(save_path) as reader:\n",
    "    \n",
    "    # lets print the readers Header-- it should only have metadata for channels 0 and 2\n",
    "    print('---EDF SUBSET HEADER---')\n",
    "    print(reader.header)\n",
    "    \n",
    "    #lets print the first 5 samples and check these against the full data\n",
    "    print('---EDF SUBSET DATA---')\n",
    "    print(reader.read(0,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6852a8",
   "metadata": {},
   "source": [
    "><s><font size=3>The Header is only showing data for two channels, which is a good sign. Now, let's check the data.</s>\n",
    "    \n",
    "<font color='red'>Both the header and the data appear to contain only the metadata and data for channels 0 and 2. Now lets check that is the case by examining all the data against the original 'recording_001.edf' demo file.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c66609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#second_file_reader.read(0, 5) remove  me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f71fe",
   "metadata": {},
   "source": [
    "><s><font size=3>That all looks well and good. But to be absolutely sure, <b>let's extract the first and third channels from our initial Reader, and compare them to our new Reader's data directly.</b></s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03d7de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do the arrays match? ->  True\n"
     ]
    }
   ],
   "source": [
    "# State what your doing and don't use trailing \",\"\n",
    "#print(\"Do the records match? \", np.allclose(reader.read(0, channels=[0, 2]), second_file_reader.read(0,)))\n",
    "\n",
    "#fp is the still the filepath to recording_001.edf\n",
    "with edf.Reader(fp) as reader:\n",
    "    \n",
    "    #read all 4 channels from the file\n",
    "    all_data = reader.read(0)\n",
    "\n",
    "#save_path is where the subset_001.edf resides\n",
    "with edf.Reader(save_path) as reader:\n",
    "    \n",
    "    #read the 2 channels from the subset file\n",
    "    two_ch_data = reader.read(0)\n",
    "    \n",
    "print(\"Do the arrays match? -> \", np.allclose(all_data[[0,2], :], two_ch_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4b760",
   "metadata": {},
   "source": [
    "## EDF Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cace1",
   "metadata": {},
   "source": [
    "><font size=3>EDF Files will contain headers and data records as we have just seen. There is, in fact, a third piece of information that may be stored onto the EDF file alongside the raw data, the annotations. <font color=firebrick>Annotations</font> are extra labels that can be used to denote significant events or time periods in the EEG data. Examples may include recording artifacts to be removed, or periods of the subject being awake/asleep.\n",
    ">\n",
    "><font size=3>Annotations can be used to separate data by different needs, (e.g. filtering out all noted times where the subject is asleep.) Because of this, openseize provides a special Annotation object type to read these out of the EDF file and work with them directly. \n",
    ">    \n",
    "><font size=3>Annotations can come in various formats, but for now, we will look only at the <font color=firebrick>Pinnacle</font> template of annotation, for which we have provided a specific Annotation object. <b>Let's take a look at what this Pinnacle Annotation looks like in openseize:</b>\n",
    "    \n",
    "<font color='red'>In addition to EDF file readers, Openseize provides annotation file readers. Typically, annotation files are comma-separated or tab-separated value text files that contain time-stamps and labels of important events that occurred during an EEG recording session. Here we will show how to open a Pinnacle format annotation TSV text file. Lets start by looking at the documentation for this annotation reader.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19991e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Pinnacle in module openseize.io.annotations:\n",
      "\n",
      "class Pinnacle(openseize.io.bases.Annotations)\n",
      " |  Pinnacle(path, **kwargs)\n",
      " |  \n",
      " |  A Pinnacle Technologies© annotations file reader.\n",
      " |  \n",
      " |  Pinnacle files store annotation data to a plain text file. This\n",
      " |  reader reads each row of this file extracting and storing annotation\n",
      " |  data to a sequence Annotation objects one per annotation (row) in the\n",
      " |  file.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Pinnacle\n",
      " |      openseize.io.bases.Annotations\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  channel(self, row)\n",
      " |      Extracts the annotation channel for a row in this file.\n",
      " |  \n",
      " |  duration(self, row)\n",
      " |      Measures the duration of an annotation for a row in this file.\n",
      " |  \n",
      " |  label(self, row)\n",
      " |      Extracts the annotation label for a row in this file.\n",
      " |  \n",
      " |  open(self, path, start=0, delimiter='\\t', **kwargs)\n",
      " |      Opens a file returning a file handle and row iterator.\n",
      " |      \n",
      " |      Args:\n",
      " |          path: str or Path instance\n",
      " |              A annotation file path location.\n",
      " |          start: int\n",
      " |              The row number of the column headers in the file.\n",
      " |          **kwargs: A valid keyword argument for CSV.DictReader builtin.\n",
      " |  \n",
      " |  time(self, row)\n",
      " |      Extracts the annotation time of a row of this file.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.io.bases.Annotations:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Return this instance as target variable of this context.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |      Closes this instance's file obj. & propagate errors by returning\n",
      " |      None.\n",
      " |  \n",
      " |  __init__(self, path, **kwargs)\n",
      " |      Initialize this Annotations reader.\n",
      " |      \n",
      " |      Args:\n",
      " |          path: str or Path instance\n",
      " |              A path location to an annotation file.\n",
      " |          **kwargs: dict\n",
      " |              Keyword args provided to Annotations open method for opening\n",
      " |              file at path\n",
      " |  \n",
      " |  close(self)\n",
      " |      Closes this instance's opened file object.\n",
      " |  \n",
      " |  read(self, labels=None)\n",
      " |      Reads annotations with labels to a list of Annotation instances.\n",
      " |      \n",
      " |      Args:\n",
      " |          labels: sequence\n",
      " |              A sequence of annotation string labels for which Annotation\n",
      " |              instances will be returned. If None, return all.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A list of Annotation dataclass instances (see Annotation).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openseize.io.bases.Annotations:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(annotations.Pinnacle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104f9372",
   "metadata": {},
   "source": [
    "><s><font size=3>As the helpfile notes, the only parameter to a new Pinnacle Annotations object is a <font color=firebrick>path</font>. This path should point directly to a Pinnacle annotation file, which is usually a comma- or tab-separated value text document. Like before, <b>we will pull down a sample annotations file form our demos repo and create a Pinnacle object from it.</b></s>\n",
    "    \n",
    "<font color='red'>To construct an annotation reader you will need to provide a path to an annotation file. This path is given to the open method (see above). Additionally, you may need to pass in a start line of the file. This describes what line the column data starts on. Lets fetch the demo file \"annotations_001.txt\" if it is not on your system already and display the file's contents.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f9aad1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Experiment ID\tExperiment\n",
      "\n",
      "1 Animal ID\tAnimal\n",
      "\n",
      "2 Researcher\tTest\n",
      "\n",
      "3 Directory path\t\n",
      "\n",
      "4 \n",
      "\n",
      "5 \n",
      "\n",
      "6 Number\tStart Time\tEnd Time\tTime From Start\tChannel\tAnnotation\n",
      "\n",
      "7 0\t08/15/20 09:59:15.215\t08/15/20 09:59:15.215\t0.0000\tALL\tStarted Recording\n",
      "\n",
      "8 1\t08/15/20 10:00:00.000\t08/15/20 10:00:00.000\t44.7850\tALL\tQi_start\n",
      "\n",
      "9 2\t08/15/20 10:00:25.000\t08/15/20 10:00:30.000\t69.7850\tALL\tgrooming\n",
      "\n",
      "10 3\t08/15/20 10:00:45.000\t08/15/20 10:00:50.000\t89.7850\tALL\tgrooming\n",
      "\n",
      "11 4\t08/15/20 10:02:15.000\t08/15/20 10:02:20.000\t179.7850\tALL\tgrooming\n",
      "\n",
      "12 5\t08/15/20 10:04:36.000\t08/15/20 10:04:41.000\t320.7850\tALL\texploring\n",
      "\n",
      "13 6\t08/15/20 10:05:50.000\t08/15/20 10:05:55.000\t394.7850\tALL\texploring\n",
      "\n",
      "14 7\t08/15/20 10:08:50.000\t08/15/20 10:08:55.000\t574.7850\tALL\trest\n",
      "\n",
      "15 8\t08/15/20 10:10:14.000\t08/15/20 10:10:19.000\t658.7850\tALL\texploring\n",
      "\n",
      "16 9\t08/15/20 10:17:10.000\t08/15/20 10:17:15.000\t1074.7850\tALL\trest\n",
      "\n",
      "17 10\t08/15/20 10:35:49.000\t08/15/20 10:35:54.000\t2193.7850\tALL\trest\n",
      "\n",
      "18 11\t08/15/20 10:40:00.000\t08/15/20 10:40:00.000\t2444.7850\tALL\tQi_stop\n",
      "\n",
      "19 12\t08/15/20 11:02:09.879\t08/15/20 11:02:09.879\t3774.6640\tALL\tStopped Recording\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#determine the local path using the locate method and download if necessary\n",
    "annotations_path = demos.paths.locate('annotations_001.txt')\n",
    "#areader = annotations.Pinnacle(annotations_path, start=6)\n",
    "\n",
    "#lets take a look at the file\n",
    "with open(annotations_path, 'r') as infile:\n",
    "    for idx, row in enumerate(infile):\n",
    "        print(idx, row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c381107",
   "metadata": {},
   "source": [
    "<font color='red'>With this path  we can now construct an Annotations reader instance. Just as with Readers and Writers an instance can (and most of the time should) be constructed as a context manager. Below we are going to construct the annotations reader starting from line 6 since that is the row containing the column headers of the file. Note this initialization argument is passed to the open method which can accept any argument that python's builtin CSV.DictReader can accept.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb628f9",
   "metadata": {},
   "source": [
    "><s><font size=3>Now that we have the Pinnacle reader, we can <b>take a look at the list of annotations in the file.</b></s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ecd73063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation(label='Started Recording', time=0.0, duration=0.0, channel='ALL')\n",
      "Annotation(label='Qi_start', time=44.785, duration=0.0, channel='ALL')\n",
      "Annotation(label='grooming', time=69.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='grooming', time=89.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='grooming', time=179.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='exploring', time=320.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='exploring', time=394.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=574.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='exploring', time=658.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=1074.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=2193.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='Qi_stop', time=2444.785, duration=0.0, channel='ALL')\n",
      "Annotation(label='Stopped Recording', time=3774.664, duration=0.0, channel='ALL')\n"
     ]
    }
   ],
   "source": [
    "#open the annotations and read all the annotations in the file using the 'read' method\n",
    "with annotations.Pinnacle(annotations_path, start=6) as reader:\n",
    "    \n",
    "    #call read to get the annotations as a sequence of Annotation instances (to be described in a moment)\n",
    "    annotes = reader.read()\n",
    "    \n",
    "#print the sequence of annotation instances\n",
    "for instance in annotes:\n",
    "    print(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "67ba84eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#areader.read() remove me"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f4d1d",
   "metadata": {},
   "source": [
    "><s><font size=3>As we can see, each annotation has been read into a unique <font color=firebrick>Annotation</font> object. We can consider the output of an Annotations Reader to be a list of these Annotation objects. Let's <b>look at a single one of these Annotations in finer detail.</b></s>\n",
    "</br>\n",
    "<font color='red'>You can see that we have fetched all of the annotations from the displayed file and stored each annotation to an Annotation instance. What is this instance? An Annotation object is a python dataclass. If you haven't seen this before, you can think of it as a simple container with '.' dot notation access to the container's contents. Lets examime the third dataclass instance.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "27597184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation(label='grooming', time=89.785, duration=5.0, channel='ALL')\n",
      "This annotation occurred at 89.785 s relative to the start time\n"
     ]
    }
   ],
   "source": [
    "#fetch the third annotation item and display it\n",
    "item = annotes[3]\n",
    "print(item)\n",
    "\n",
    "#access the items time from recording start\n",
    "print('This annotation occurred at {} s relative to the start time'.format(item.time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "59470ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE\n",
    "\n",
    "#areader = annotations.Pinnacle(path=annotations_path, start=6) # We have to reset the reader to reiterate over annotations\n",
    "#print(areader.read()[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed767d",
   "metadata": {},
   "source": [
    "><font size=3>The key pieces of information are given to us in a single Annotation instance:\n",
    ">    * <font color=firebrick>label</font> - a piece of text describing the annotation\n",
    ">    * <font color=firebrick>time</font> - the exact point in time (in seconds) from the beginning of the recording that the annotation takes place\n",
    ">    * <font color=firebrick>duration</font> - the length (in seconds) of the annotation from its start time \n",
    "    >    * <font color=firebrick>channel</font> - a list of the channels in the EEG recording that the annotation is applied to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5ba75",
   "metadata": {},
   "source": [
    "><s><font size=3>In the process of performing analysis, you may want to filter the list of annotations you have by what type of annotation it is. We use the label as the descriptor from which we can perform this filter. <b>By passing in a list of labels, you can read only the annotations you care about using the Pinnacle Reader.</b><s>\n",
    "    \n",
    "<font color='red'>In the preceeding example we read all of the annotations from the Pinnacle formatted file but the Annotations 'read' method can accept a sequence of labels to selectively read only some of the annotations. Let's show how this works on this demo annotation file.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d9b90106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation(label='exploring', time=320.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='exploring', time=394.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=574.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='exploring', time=658.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=1074.785, duration=5.0, channel='ALL')\n",
      "Annotation(label='rest', time=2193.785, duration=5.0, channel='ALL')\n"
     ]
    }
   ],
   "source": [
    "#areader = annotations.Pinnacle(path=annotations_path, start=6) # We have to reset the reader to reiterate over annotations\n",
    "#areader.read(labels=['rest', 'exploring'])\n",
    "\n",
    "#read only the annotations with labels matching either rest or exploring\n",
    "with annotations.Pinnacle(annotations_path, start=6) as reader:\n",
    "    subset_annotes = reader.read(labels=['rest', 'exploring'])\n",
    "    \n",
    "for annote in subset_annotes:\n",
    "    print(annote)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feffa78",
   "metadata": {},
   "source": [
    "## Producing from EDF Files with Annotations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec43b80e",
   "metadata": {},
   "source": [
    "><s><font size=3>Here, we filter the annotations by the labels 'exploring' and 'resting', excluding the remainder. Now aside from solely filtering the annotations themselves, we can use them to also filter EEG data via a process called <i><b>masking</b></i>. Masking refers to applying a filter to the data so that only portions of it are read out, and the rest ignored. The mask itself is just <b>an array of True/False values, corresponding to each sample in the EEG data</b>, determining whether that sample should be kept or removed. Applying a mask to an EDF file can be done with the use of a producer (for more details, see the demo on Producers).</s>\n",
    "> <font color='red'>Two important components of an Annotation instance is the time and duration attributes. These attributes allow for selective filtering of EEG data returned from either a Reader or a producer. To do this, the annotation dataclass  instances are converted into a boolean mask that can pick out samples of data to keep or discard. Here we will demonstrate how to construct a boolean mask from a list of annotation instances and use that mask to filter a producer's yielded numpy arrays. Further details can be found in the producer demo. \n",
    ">\n",
    "><font size=3>The annotations module provides a method for generating a mask automatically from a series of annotation objects, the <font color=firebrick>as_mask</font> method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "43f4475f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function as_mask in module openseize.io.annotations:\n",
      "\n",
      "as_mask(annotations, size, fs, include=True)\n",
      "    Convert a sequence of annotation objects into a 1-D boolean array. \n",
      "    \n",
      "    Args:\n",
      "        annotations: list\n",
      "            A sequence of annotation objects to convert to a mask.\n",
      "        size: int\n",
      "            The length of the boolean array to return.\n",
      "        fs: int\n",
      "            The sampling rate in Hz of the recorded EEG.\n",
      "        include: bool\n",
      "            A boolean to determine if annotations should be set to True or\n",
      "            False in the returned array. Default is True, meaning all values\n",
      "            are False in the returned array except for samples where the\n",
      "            annotations are located.\n",
      "    \n",
      "    Returns:\n",
      "        A 1-D boolean array of length size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(annotations.as_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccd97d2",
   "metadata": {},
   "source": [
    "><s><font size=3>This method takes in <font color=firebrick>a list of Annotation objects</font>, the <font color=firebrick>size</font> of the mask to create (usually the number of samples in the EDF file you wish to mask), and the <font color=firebrick>sampling rate</font> of the recording. In addition, you can apply an <font color=firebrick>include</font> parameter, to determine if the annotations you pass in are meant to come back as True or False (this depends on if your goal is to filter for or against the annotated time periods).</s>\n",
    "><font color='red'>To construct a mask, <font color=firebrick>as_mask</font> needs a sequence of annotation dataclass instances, the size of the mask along the sample axis, the sampling rate to convert the annotation times to samples, and a boolean \"include\" parameter which determines if the annotations should be kept (True) or discarded (False) from the EEG data.\n",
    "><font size=3>Here, as an example, <b>we create such a mask.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0bdee8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DELETE\n",
    "#areader = annotations.Pinnacle(path=annotations_path, start=6)\n",
    "\n",
    "# Create mask, \n",
    "#mask = annotations.as_mask(areader.read(), size=reader.shape[-1], fs=1000, include=True)\n",
    "\n",
    "# Check how many values in the recording mask to False or True\n",
    "#np.unique(mask, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the annotations from the demo file\n",
    "with annotations.Pinnacle(annotations_path, start=6) as reader:\n",
    "    subset_annotes = reader.read(labels=['rest', 'exploring'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df93db70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the mask; fp is the still the filepath to recording_001.edf; size and fs can be fetched from reader\n",
    "with edf.Reader(fp) as reader:    \n",
    "    size = reader.shape[-1]\n",
    "    fs = reader.header.samples_per_record[0]\n",
    "    \n",
    "mask = annotations.as_mask(subset_annotes, size, fs, include=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91209e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False False False False False False False False False]\n",
      "[False False False False False  True  True  True  True  True]\n",
      "Expected number of samples to keep is 150000 \n",
      "Actual number kept is 150000\n"
     ]
    }
   ],
   "source": [
    "#print the first 10 values of the mask\n",
    "print(mask[:10])\n",
    "\n",
    "#The first True values should occur at 320.785 secs * 5000 Hz since fs=5000 and the first annotation \n",
    "#(see above occurs at 320.785). Lets confirm this by print 10 samples around this sample\n",
    "start = int(320.785 * 5000)\n",
    "print(mask[start-5: start+5])\n",
    "\n",
    "#lastly lets print out the total number of samples we will keep\n",
    "expected = len(subset_annotes) * 5 * 5000 # each annote is 5 secs @ 5 kHz\n",
    "actual = np.count_nonzero(mask)\n",
    "print('Expected number of samples to keep is {} \\nActual number kept is {}'.format(expected, actual))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c9b0f",
   "metadata": {},
   "source": [
    "><s><font size=3>Here, we can see that filtering out any records that are not annotated results in 45000 records or 45 seconds of True values in our mask. This mask can then be applied to a producer to filter out these results directly from an EDF file.</s>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "70d07c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUild a producer with this mask and show that it has the expected shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40792f54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
