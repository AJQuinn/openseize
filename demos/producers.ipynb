{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33424ff2",
   "metadata": {},
   "source": [
    "                                                                                                 MSC & JB 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cca2d",
   "metadata": {},
   "source": [
    "# Producers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01b76b",
   "metadata": {},
   "source": [
    "- [**Imports**](#Imports)\n",
    "- [**Introduction**](#Introduction)\n",
    "- [**Creation Routines**](#Creation-Routines)\n",
    "    - [**Producers From Arrays**](#Producers-From-Arrays)\n",
    "    - [**Producers From Sequences**](#Producers-From-Sequences)\n",
    "    - [**Producers From  Files**](#Producers-From-Files)\n",
    "    - [**Producers From Generating Functions**](#Producers-From-Generating-Functions)\n",
    "    - [**Producers From Producers**](#Producers-From-Producers)\n",
    "    - [**Masked Producers**](#Masked-Producers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e20be3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c7206b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openseize import producer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17356ab3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0395d",
   "metadata": {},
   "source": [
    "> <font size=3> **Problem statement** <br/><br/> The size of an EEG  dataset depends on three factors, the number of signals acquired, the sampling rate of each signal and the duration of the measurement. Recent advances in electrode and data acquistion hardware allow for increases in each of these factors such that the resulting dataset may not fit into the virtual (RAM) memory of a user's computer. \n",
    "    <br/><br/>  To address this, openseize uses an iterable object -- the <font color='darkcyan'> **producer, an object that sequentially produces numpy arrays from a data source** </font>. This data source can be a sequence, an ndarray, a file stored to disk, or even a generator function that produces data itself. In this demo, we will cover producer creation routines attributes and methods.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc2077",
   "metadata": {},
   "source": [
    "## Creation Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3069cb",
   "metadata": {},
   "source": [
    "> <font size=3> All producers, no matter the data source, are constructed using the produce() function. To see what arguments are needed to build a producer we can look at the producer function documentation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2cd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function producer in module openseize.core.producer:\n",
      "\n",
      "producer(data, chunksize, axis, shape=None, mask=None, **kwargs)\n",
      "    Constructs an iterable that produces ndarrays of length chunksize\n",
      "    along axis during iteration.\n",
      "    \n",
      "    This constructor returns an object that is capable of producing ndarrays\n",
      "    or masked ndarrays during iteration from a single ndarray, a sequence of\n",
      "    ndarrays, a file Reader instance (see io.bases.Reader), an ndarray \n",
      "    generating function, or a pre-existing producer of ndarrays. The \n",
      "    produced ndarrays from this object will have length chunksize along axis.\n",
      "    \n",
      "    Args:\n",
      "        data:\n",
      "            An object from which ndarrays will be produced from. Supported\n",
      "            types are Reader instances, ndarrays, sequence of ndarrays, \n",
      "            generating functions yielding ndarrays, or a producer of \n",
      "            ndarrays. For sequences and generator functions it is\n",
      "            required that each subarray has the same shape along all axes \n",
      "            except for the axis along which chunks will be produced. \n",
      "        chunksize: int\n",
      "            The desired length along axis of each produced ndarray. \n",
      "        axis: int\n",
      "            The sample axis of data that will be partitioned into \n",
      "            chunks of length chunksize.\n",
      "        shape: tuple or None\n",
      "            The combined shape of all ndarrays from this producer. This\n",
      "            parameter is only required when object is a generating function\n",
      "            and will be ignored otherwise.\n",
      "        mask: 1-D boolean array\n",
      "            A boolean describing which values of data along axis\n",
      "            should by produced. Values that are True will be produced and\n",
      "            values that are False will be ignored. If None (Default),\n",
      "            producer will produce all values from object.\n",
      "        kwargs: dict\n",
      "            Keyword arguments specific to data type that ndarrays will be\n",
      "            produced from. \n",
      "            For Reader instances, valid kwargs are channels\n",
      "            and padvalue (see io.bases.Readers and io.edf.Reader)\n",
      "            For generating functions, all the positional and keyword\n",
      "            arguments must be passed to the function through these kwargs to\n",
      "            avoid name collisions with the producer func arguments.\n",
      "    \n",
      "    Returns: An iterable of ndarrays of shape chunksize along axis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(producer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ff6e2",
   "metadata": {},
   "source": [
    "> <font size=3>So the producer function needs a <font color='darkcyan'>data</font> source, a <font color='darkcyan'>chunksize</font> describing the number of samples that should be included in each produced subarray, the <font color='darkcyan'>axis</font> along which samples lie and <font color='darkcyan'>possibly a shape and mask</font>. We will cover each of these parameters in detail in this demo.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb189cc6",
   "metadata": {},
   "source": [
    "### Producers From Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3763f8",
   "metadata": {},
   "source": [
    "> <font size=3>To create a producer from an array may seem silly. *Isn't the array already in memory?* Well, yes it is but maybe that array is consuming a lot of your memory and you can't do anything with the array. By creating a producer, you can work with the produced values using any of the openseize functions (downsample, filter, etc) while still holding the array in-memory. <br/><br/> **Let's make an array and then create a producer to demonstrate this utility.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5eac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is using = 32.0 MB\n"
     ]
    }
   ],
   "source": [
    "# create a reproducible random data array with 4 channels and 1 million samples along axis=1\n",
    "rng = np.random.default_rng(1234)\n",
    "data = rng.random((4, 1000000))\n",
    "\n",
    "# lets also print data's memory consumption\n",
    "print('data is using = {} MB'.format((data.size * data.itemsize)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc43f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro is using = 48 Bytes\n"
     ]
    }
   ],
   "source": [
    "# build a producer declaring that we want the producer to yield arrays of size 300000 \n",
    "# using the samples along the last axis\n",
    "pro = producer(data, chunksize=300000, axis=-1)\n",
    "\n",
    "# lets checkout the producer's memory consumption\n",
    "print('pro is using = {} Bytes'.format(sys.getsizeof(pro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53521d3e",
   "metadata": {},
   "source": [
    "><font size=3>This is the first important point about producers. <font color='darkcyan'>Producers do not store data, they are iterables that know how to yield data to you on-the-fly.</font> **Let's see what the producers attributes are.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "249e3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayProducer Object\n",
      "---Attributes & Properties---\n",
      "{'data': array([[0.97669977, 0.38019574, 0.92324623, ..., 0.02049864, 0.84033509,\n",
      "        0.07061386],\n",
      "       [0.32584251, 0.01559622, 0.16734471, ..., 0.48613722, 0.13466647,\n",
      "        0.78129557],\n",
      "       [0.45169665, 0.44011763, 0.0325013 , ..., 0.86914401, 0.5904367 ,\n",
      "        0.4616979 ],\n",
      "       [0.84830865, 0.97995714, 0.63405179, ..., 0.7236714 , 0.80536627,\n",
      "        0.77495984]]),\n",
      " 'axis': -1,\n",
      " 'kwargs': {},\n",
      " 'chunksize': 300000,\n",
      " 'shape': (4, 1000000)}\n",
      "\n",
      "Type help(ArrayProducer) for full documentation\n"
     ]
    }
   ],
   "source": [
    "print(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817fcf3b",
   "metadata": {},
   "source": [
    "><font size=3>The producer instance is holding a reference to the data array, the sample axis, the chunksize of subarrays that will be produced and the shape of the referenced data. Let's try to get each subarray from the producer. <font color='firebrick'>*Wait.. how do we do that?*</font>. \n",
    "    <br/>\n",
    "    <br/>Since the producer is an iterable, you can access each subarray just like any iterable, Any method that triggers python's iteration protocol will give you the subarrays in the producer. This could be a for-loop, a list comprehension, or an explicit call to the iter and next builtin methods. **Lets access each produced array in a loop.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c0b2b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0, shape=(4, 300000)\n",
      "[[0.97669977 0.38019574 0.92324623 0.26169242 0.31909706]\n",
      " [0.32584251 0.01559622 0.16734471 0.12427613 0.25749222]\n",
      " [0.45169665 0.44011763 0.0325013  0.02906749 0.20707769]\n",
      " [0.84830865 0.97995714 0.63405179 0.71921724 0.34165105]]\n",
      "Array 1, shape=(4, 300000)\n",
      "[[0.19975295 0.38469445 0.31663237 0.32026263 0.85713905]\n",
      " [0.68094421 0.67678136 0.02969927 0.90235448 0.79731081]\n",
      " [0.3700237  0.60763138 0.04216831 0.57699506 0.04456521]\n",
      " [0.54071085 0.82855925 0.09775676 0.03968656 0.65453465]]\n",
      "Array 2, shape=(4, 300000)\n",
      "[[0.92858655 0.05528663 0.88124263 0.28606888 0.54164412]\n",
      " [0.95592965 0.80143229 0.09263899 0.72895997 0.85988591]\n",
      " [0.7104101  0.58855675 0.11348623 0.5171883  0.90972664]\n",
      " [0.48743344 0.00490091 0.20384552 0.91139126 0.04721849]]\n",
      "Array 3, shape=(4, 100000)\n",
      "[[0.78483056 0.93115015 0.41382943 0.38030702 0.75412888]\n",
      " [0.4725766  0.14425412 0.15515715 0.71459954 0.30351422]\n",
      " [0.34821652 0.89459182 0.1399783  0.21133067 0.58058115]\n",
      " [0.78146378 0.0234853  0.10318636 0.26773979 0.75606789]]\n"
     ]
    }
   ],
   "source": [
    "# loop to access each subarray printing it's shape and first 5 of samples for each channel\n",
    "for idx, subarr in enumerate(pro):\n",
    "    print('Array {}, shape={}'.format(idx, subarr.shape))\n",
    "    print(subarr[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad75f2",
   "metadata": {},
   "source": [
    "><font size=3>Be sure not to miss that the last array the producer yielded was smaller than the previous 3. Why? Remember the data shape is (4, 1e6) and 1e6 is not perfectly divisible by 300,000. In fact, the last array yielded is of course 1e6 % 300,000 = 100,000 samples long. Important question **Is the producer exhausted?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4fa849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0, shape=(4, 300000)\n",
      "Array 1, shape=(4, 300000)\n",
      "Array 2, shape=(4, 300000)\n",
      "Array 3, shape=(4, 100000)\n"
     ]
    }
   ],
   "source": [
    "# test if producer can produce again\n",
    "for idx, subarr in enumerate(pro):\n",
    "    print('Array {}, shape={}'.format(idx, subarr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde004f",
   "metadata": {},
   "source": [
    "><font size=3>This is critical, <font color='darkcyan'>the producer is an iterable not a one-shot iterator. It can go through the data as many times as you need.</font> \n",
    "    <br/><br/> Now if you are skeptical (like any good scientist) you are probably wondering. *How do I know that the produced values **exactly** match the original data source.* **Let's demonstrate that all the produced data exactly matches the original data source.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "492adc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingers crossed.. Do they match? -> True\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the  produced arrays match the original data source 'data'\n",
    "# concatenate all produced subarrays along the last sample axis.\n",
    "produced_array = np.concatenate([subarr for subarr in pro], axis=1)\n",
    "\n",
    "#now test if the combined produced arrays match the original data array\n",
    "print('Fingers crossed.. Do they match? -> {}'.format(np.allclose(produced_array, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76e02d",
   "metadata": {},
   "source": [
    "> <font size=3> Our method of testing array equality required us to concatenate the produced arrays. Since converting a producer to an ndarry is likely something you'll need often, it is a formal method of each producer instance called  *to_array*. **Let's call this important method and repeat our test.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5140de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match? -> True\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the  produced arrays match the original data source 'data'\n",
    "# concatenate all produced subarrays along the last sample axis using the producer's to_array method.\n",
    "produced_array = pro.to_array()\n",
    "\n",
    "#now test if the combined produced arrays match the original data array\n",
    "print('Match? -> {}'.format(np.allclose(produced_array, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa189a",
   "metadata": {},
   "source": [
    "><font size=3>Of course this was just one test. If you need to see more tests to be convinced, please see openseize.core.tests.producer_tests for the formal pytesting.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442cc3f",
   "metadata": {},
   "source": [
    "## Producers From Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a03fc",
   "metadata": {},
   "source": [
    "><font size=3>As you might guess from our discussion on producers built from arrays, producers can be built from any sequence. **Let's show that producers can be built from sequences.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc84191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fun sequence from monty-python\n",
    "my_seq = [\"(Knight) Tis but a scratch.\",\n",
    "          \"(Arthur) A scratch? Your arm's off!\",\n",
    "          \"(Knight) No, it isn't.\",\n",
    "          \"(Arthur) Well, what's that then?\"]\n",
    "# convert it to a scene producer\n",
    "scene = producer(my_seq, chunksize=1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5036af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(Knight) Tis but a scratch.']\n",
      "[\"(Arthur) A scratch? Your arm's off!\"]\n",
      "[\"(Knight) No, it isn't.\"]\n",
      "[\"(Arthur) Well, what's that then?\"]\n"
     ]
    }
   ],
   "source": [
    "# play the scene out\n",
    "for dialog in scene:\n",
    "    print(dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60234f64",
   "metadata": {},
   "source": [
    "><font size=3>There is no restriction on the datatype that can be produced as the above snippet demonstrates. As such, you might find producers useful for other large tasks that you need to break into subproblems.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe319b",
   "metadata": {},
   "source": [
    "## Producers From Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a7b9b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
