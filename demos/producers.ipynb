{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33424ff2",
   "metadata": {},
   "source": [
    "                                                                                                 MSC & JB 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1cca2d",
   "metadata": {},
   "source": [
    "# Producers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01b76b",
   "metadata": {},
   "source": [
    "- [**Imports**](#Imports)\n",
    "- [**Introduction**](#Introduction)\n",
    "- [**Creation Routines**](#Creation-Routines)\n",
    "    - [**Producers From Arrays**](#Producers-From-Arrays)\n",
    "    - [**Producers From Sequences**](#Producers-From-Sequences)\n",
    "    - [**Producers From  Files**](#Producers-From-Files)\n",
    "    - [**Producers From Generating Functions**](#Producers-From-Generating-Functions)\n",
    "    - [**Producers From Producers**](#Producers-From-Producers)\n",
    "    - [**Masked Producers**](#Masked-Producers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e20be3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c7206b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from openseize import producer\n",
    "from openseize import demos\n",
    "from openseize.io import edf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17356ab3",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d0395d",
   "metadata": {},
   "source": [
    "><font size=3> **Problem statement** <br/><br/> The size of an EEG  dataset depends on three factors, the number of signals acquired, the sampling rate of each signal and the duration of the measurement. Recent advances in electrode and data acquistion hardware allow for increases in each of these factors such that the resulting dataset may not fit into the virtual (RAM) memory of a user's computer. </font>\n",
    ">\n",
    "><font size=3>To address this, openseize uses an iterable object -- the <font color='darkcyan'> **producer, an object that sequentially produces numpy arrays from a data source**</font>. This data source can be a sequence, an ndarray, a file stored to disk, or even a generator function that produces data itself. In this demo, we will cover producer creation routines attributes and methods.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc2077",
   "metadata": {},
   "source": [
    "## Creation Routines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3069cb",
   "metadata": {},
   "source": [
    "> <font size=3> All producers, no matter the data source, are constructed using the produce() function. To see what arguments are needed to build a producer we can look at the producer function documentation.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2cd834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function producer in module openseize.core.producer:\n",
      "\n",
      "producer(data, chunksize, axis, shape=None, mask=None, **kwargs)\n",
      "    Constructs an iterable that produces ndarrays of length chunksize\n",
      "    along axis during iteration.\n",
      "    \n",
      "    This constructor returns an object that is capable of producing ndarrays\n",
      "    or masked ndarrays during iteration from a single ndarray, a sequence of\n",
      "    ndarrays, a file Reader instance (see io.bases.Reader), an ndarray \n",
      "    generating function, or a pre-existing producer of ndarrays. The \n",
      "    produced ndarrays from this object will have length chunksize along axis.\n",
      "    \n",
      "    Args:\n",
      "        data:\n",
      "            An object from which ndarrays will be produced from. Supported\n",
      "            types are Reader instances, ndarrays, sequence of ndarrays, \n",
      "            generating functions yielding ndarrays, or a producer of \n",
      "            ndarrays. For sequences and generator functions it is\n",
      "            required that each subarray has the same shape along all axes \n",
      "            except for the axis along which chunks will be produced. \n",
      "        chunksize: int\n",
      "            The desired length along axis of each produced ndarray. \n",
      "        axis: int\n",
      "            The sample axis of data that will be partitioned into \n",
      "            chunks of length chunksize.\n",
      "        shape: tuple or None\n",
      "            The combined shape of all ndarrays from this producer. This\n",
      "            parameter is only required when object is a generating function\n",
      "            and will be ignored otherwise.\n",
      "        mask: 1-D boolean array\n",
      "            A boolean describing which values of data along axis\n",
      "            should by produced. Values that are True will be produced and\n",
      "            values that are False will be ignored. If None (Default),\n",
      "            producer will produce all values from object.\n",
      "        kwargs: dict\n",
      "            Keyword arguments specific to data type that ndarrays will be\n",
      "            produced from. \n",
      "            For Reader instances, valid kwargs are channels\n",
      "            and padvalue (see io.bases.Readers and io.edf.Reader)\n",
      "            For generating functions, all the positional and keyword\n",
      "            arguments must be passed to the function through these kwargs to\n",
      "            avoid name collisions with the producer func arguments.\n",
      "    \n",
      "    Returns: An iterable of ndarrays of shape chunksize along axis.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(producer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620ff6e2",
   "metadata": {},
   "source": [
    "> <font size=3>So the producer function needs a <font color='darkcyan'>data</font> source, a <font color='darkcyan'>chunksize</font> describing the number of samples that should be included in each produced subarray, the <font color='darkcyan'>axis</font> along which samples lie and <font color='darkcyan'>possibly a shape and mask</font>. We will cover each of these parameters in detail in this demo.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb189cc6",
   "metadata": {},
   "source": [
    "### Producers From Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3763f8",
   "metadata": {},
   "source": [
    "> <font size=3>To create a producer from an array may seem silly. *Isn't the array already in memory?* Well, yes it is but maybe that array is consuming a lot of your memory and you can't do anything with the array. By creating a producer, you can work with the produced values using any of the openseize functions (downsample, filter, etc) while still holding the array in-memory. <br/><br/> **Let's make an array and then create a producer to demonstrate this utility.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c5eac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data is using = 32.0 MB\n"
     ]
    }
   ],
   "source": [
    "# create a reproducible random data array with 4 channels and 1 million samples along axis=1\n",
    "rng = np.random.default_rng(1234)\n",
    "data = rng.random((4, 1000000))\n",
    "\n",
    "# lets also print data's memory consumption\n",
    "print('data is using = {} MB'.format((data.size * data.itemsize)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc43f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pro is using = 48 Bytes\n"
     ]
    }
   ],
   "source": [
    "# build a producer declaring that we want the producer to yield arrays of size 300000 \n",
    "# using the samples along the last axis\n",
    "pro = producer(data, chunksize=300000, axis=-1)\n",
    "\n",
    "# lets checkout the producer's memory consumption\n",
    "print('pro is using = {} Bytes'.format(sys.getsizeof(pro)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53521d3e",
   "metadata": {},
   "source": [
    "><font size=3>This is the first important point about producers. <font color='darkcyan'>Producers do not store data, they are iterables that know how to yield data to you on-the-fly.</font> **Let's see what the producers attributes are.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "249e3849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ArrayProducer Object\n",
      "---Attributes & Properties---\n",
      "{'data': array([[0.97669977, 0.38019574, 0.92324623, ..., 0.02049864, 0.84033509,\n",
      "        0.07061386],\n",
      "       [0.32584251, 0.01559622, 0.16734471, ..., 0.48613722, 0.13466647,\n",
      "        0.78129557],\n",
      "       [0.45169665, 0.44011763, 0.0325013 , ..., 0.86914401, 0.5904367 ,\n",
      "        0.4616979 ],\n",
      "       [0.84830865, 0.97995714, 0.63405179, ..., 0.7236714 , 0.80536627,\n",
      "        0.77495984]]),\n",
      " 'axis': -1,\n",
      " 'kwargs': {},\n",
      " 'chunksize': 300000,\n",
      " 'shape': (4, 1000000)}\n",
      "\n",
      "Type help(ArrayProducer) for full documentation\n"
     ]
    }
   ],
   "source": [
    "print(pro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817fcf3b",
   "metadata": {},
   "source": [
    "><font size=3>The producer instance is holding a reference to the data array, the sample axis, the chunksize of subarrays that will be produced and the shape of the referenced data. Let's try to get each subarray from the producer. <font color='firebrick'>*Wait.. how do we do that?*</font>. \n",
    "    <br/>\n",
    "    <br/>Since the producer is an iterable, you can access each subarray just like any iterable, Any method that triggers python's iteration protocol will give you the subarrays in the producer. This could be a for-loop, a list comprehension, or an explicit call to the iter and next builtin methods. **Lets access each produced array in a loop.** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c0b2b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0, shape=(4, 300000)\n",
      "[[0.97669977 0.38019574 0.92324623 0.26169242 0.31909706]\n",
      " [0.32584251 0.01559622 0.16734471 0.12427613 0.25749222]\n",
      " [0.45169665 0.44011763 0.0325013  0.02906749 0.20707769]\n",
      " [0.84830865 0.97995714 0.63405179 0.71921724 0.34165105]]\n",
      "Array 1, shape=(4, 300000)\n",
      "[[0.19975295 0.38469445 0.31663237 0.32026263 0.85713905]\n",
      " [0.68094421 0.67678136 0.02969927 0.90235448 0.79731081]\n",
      " [0.3700237  0.60763138 0.04216831 0.57699506 0.04456521]\n",
      " [0.54071085 0.82855925 0.09775676 0.03968656 0.65453465]]\n",
      "Array 2, shape=(4, 300000)\n",
      "[[0.92858655 0.05528663 0.88124263 0.28606888 0.54164412]\n",
      " [0.95592965 0.80143229 0.09263899 0.72895997 0.85988591]\n",
      " [0.7104101  0.58855675 0.11348623 0.5171883  0.90972664]\n",
      " [0.48743344 0.00490091 0.20384552 0.91139126 0.04721849]]\n",
      "Array 3, shape=(4, 100000)\n",
      "[[0.78483056 0.93115015 0.41382943 0.38030702 0.75412888]\n",
      " [0.4725766  0.14425412 0.15515715 0.71459954 0.30351422]\n",
      " [0.34821652 0.89459182 0.1399783  0.21133067 0.58058115]\n",
      " [0.78146378 0.0234853  0.10318636 0.26773979 0.75606789]]\n"
     ]
    }
   ],
   "source": [
    "# loop to access each subarray printing it's shape and first 5 of samples for each channel\n",
    "for idx, subarr in enumerate(pro):\n",
    "    print('Array {}, shape={}'.format(idx, subarr.shape))\n",
    "    print(subarr[:, :5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ad75f2",
   "metadata": {},
   "source": [
    "><font size=3>Be sure not to miss that the last array the producer yielded was smaller than the previous 3. Why? Remember the data shape is (4, 1e6) and 1e6 is not perfectly divisible by 300,000. In fact, the last array yielded is of course 1e6 % 300,000 = 100,000 samples long. Important question **Is the producer exhausted?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff4fa849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array 0, shape=(4, 300000)\n",
      "Array 1, shape=(4, 300000)\n",
      "Array 2, shape=(4, 300000)\n",
      "Array 3, shape=(4, 100000)\n"
     ]
    }
   ],
   "source": [
    "# test if producer can produce again\n",
    "for idx, subarr in enumerate(pro):\n",
    "    print('Array {}, shape={}'.format(idx, subarr.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dde004f",
   "metadata": {},
   "source": [
    "><font size=3>This is critical, <font color='darkcyan'>the producer is an iterable not a one-shot iterator. It can go through the data as many times as you need.</font> \n",
    "    <br/><br/> Now if you are skeptical (like any good scientist) you are probably wondering. *How do I know that the produced values **exactly** match the original data source.* **Let's demonstrate that all the produced data exactly matches the original data source.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "492adc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fingers crossed.. Do they match? -> True\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the  produced arrays match the original data source 'data'\n",
    "# concatenate all produced subarrays along the last sample axis.\n",
    "produced_array = np.concatenate([subarr for subarr in pro], axis=1)\n",
    "\n",
    "#now test if the combined produced arrays match the original data array\n",
    "print('Fingers crossed.. Do they match? -> {}'.format(np.allclose(produced_array, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df76e02d",
   "metadata": {},
   "source": [
    "> <font size=3> Our method of testing array equality required us to concatenate the produced arrays. Since converting a producer to an ndarry is likely something you'll need often, it is a formal method of each producer instance called  *to_array*. **Let's call this important method and repeat our test.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5140de88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Match? -> True\n"
     ]
    }
   ],
   "source": [
    "# demonstrate that the  produced arrays match the original data source 'data'\n",
    "# concatenate all produced subarrays along the last sample axis using the producer's to_array method.\n",
    "produced_array = pro.to_array()\n",
    "\n",
    "#now test if the combined produced arrays match the original data array\n",
    "print('Match? -> {}'.format(np.allclose(produced_array, data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa189a",
   "metadata": {},
   "source": [
    "><font size=3>Of course this was just one test. If you need to see more tests to be convinced, please see openseize.core.tests.producer_tests for the formal pytesting.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442cc3f",
   "metadata": {},
   "source": [
    "## Producers From Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a03fc",
   "metadata": {},
   "source": [
    "><font size=3>As you might guess from our discussion on producers built from arrays, producers can be built from any sequence. **Let's show that producers can be built from sequences.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bc84191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a fun sequence from monty-python\n",
    "my_seq = [\"(Knight) Tis but a scratch.\",\n",
    "          \"(Arthur) A scratch? Your arm's off!\",\n",
    "          \"(Knight) No, it isn't.\",\n",
    "          \"(Arthur) Well, what's that then?\"]\n",
    "# convert it to a scene producer\n",
    "scene = producer(my_seq, chunksize=1, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5036af27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(Knight) Tis but a scratch.']\n",
      "[\"(Arthur) A scratch? Your arm's off!\"]\n",
      "[\"(Knight) No, it isn't.\"]\n",
      "[\"(Arthur) Well, what's that then?\"]\n"
     ]
    }
   ],
   "source": [
    "# play the scene out\n",
    "for dialog in scene:\n",
    "    print(dialog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60234f64",
   "metadata": {},
   "source": [
    "><font size=3>There is no restriction on the datatype that can be produced as the above snippet demonstrates. As such, you might find producers useful for other large tasks that you need to break into subproblems.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe319b",
   "metadata": {},
   "source": [
    "## Producers From Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3756276",
   "metadata": {},
   "source": [
    "><font size=3>Producing data from a file stored to disk that is too large to fit into virtual memory is one of the  most important use cases for producers. Here we are going to open a European data format(+) binary file type and produce arrays from it. A detailed demo of this important file reader can be found in the file_reading demo.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71640f25",
   "metadata": {},
   "source": [
    "### Demo Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9f6e6e",
   "metadata": {},
   "source": [
    "><font size=3>In order to produce from a file, we will need demo data. Openseize includes a sample edf file called *recording_001.edf*. <font color='darkcyan'>Where is this file?</font>\n",
    ">\n",
    "><font size=3>When we imported the demos module, we got a paths object that has two methods. The <font color='firebrick'>*available*</font> method list all the datasets available in the local demos/data directory as well as the demo data available in a remote Zenodo repository.The <font color='firebrick'>*locate*</font> method will return a local filepath to a named dataset. To do this, locate may need to download the data first depending on whether the data file is already on your system.</font> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e54e0658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Available demo data files & location---\n",
      "------------------------------------------\n",
      "alignments.pkl                 'https://zenodo.or...5ad/alignments.pkl'\n",
      "behavior_df.pkl                'https://zenodo.or...ad/behavior_df.pkl'\n",
      "correlated_pairs_df.pkl        'https://zenodo.or...lated_pairs_df.pkl'\n",
      "dredd_behavior.pkl             'https://zenodo.or...dredd_behavior.pkl'\n",
      "dredd_behavior.xlsx            'https://zenodo.or...redd_behavior.xlsx'\n",
      "dredd_freezes_df.pkl           'https://zenodo.or...edd_freezes_df.pkl'\n",
      "high_degree_df.pkl             'https://zenodo.or...high_degree_df.pkl'\n",
      "N006_wt_basis.npz              'https://zenodo.or.../N006_wt_basis.npz'\n",
      "N006_wt_cxtbasis.pkl           'https://zenodo.or...06_wt_cxtbasis.pkl'\n",
      "N006_wt_cxtsources.pkl         'https://zenodo.or..._wt_cxtsources.pkl'\n",
      "N006_wt_rois.pkl               'https://zenodo.or...d/N006_wt_rois.pkl'\n",
      "N006_wt_sources.npy            'https://zenodo.or...006_wt_sources.npy'\n",
      "N019_wt_basis.npz              'https://zenodo.or.../N019_wt_basis.npz'\n",
      "N019_wt_sources.npy            'https://zenodo.or...019_wt_sources.npy'\n",
      "P80_animals.pkl                'https://zenodo.or...ad/P80_animals.pkl'\n",
      "pc_sipscs_amps.pkl             'https://zenodo.or...pc_sipscs_amps.pkl'\n",
      "pc_sipscs_freqs.pkl            'https://zenodo.or...c_sipscs_freqs.pkl'\n",
      "rois_df.pkl                    'https://zenodo.or...4ec5ad/rois_df.pkl'\n",
      "signals_df.pkl                 'https://zenodo.or...5ad/signals_df.pkl'\n",
      "som_behavior_df.pkl            'https://zenodo.or...om_behavior_df.pkl'\n",
      "som_sepsc_amps.pkl             'https://zenodo.or...som_sepsc_amps.pkl'\n",
      "som_sepsc_freqs.pkl            'https://zenodo.or...om_sepsc_freqs.pkl'\n",
      "som_signals_df.pkl             'https://zenodo.or...som_signals_df.pkl'\n",
      "ssn33_sstcre_basis.npz         'https://zenodo.or...3_sstcre_basis.npz'\n",
      "ssn33_sstcre_sources.npy       'https://zenodo.or...sstcre_sources.npy'\n",
      "5872_Left_group A.txt          '/home/matt/python...2_Left_group A.txt'\n",
      "recording_001.edf              '/home/matt/python.../recording_001.edf'\n",
      "CW0259_SWDs.npy                '/home/matt/python...ta/CW0259_SWDs.npy'\n",
      "annotations_001.txt            '/home/matt/python...nnotations_001.txt'\n",
      "5872_Left_group A.edf          '/home/matt/python...2_Left_group A.edf'\n"
     ]
    }
   ],
   "source": [
    "# check out the available demo data including with openseize\n",
    "# this will include any local data in demos/data and remote data stored at openseizes Zenodo repository.\n",
    "demos.paths.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1a8af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we see the recording_001.edf is on Zenodo but not in our local data\n",
    "# this should open a confirmation box and start your download\n",
    "recording_path = demos.paths.locate('recording_001.edf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce85d4e3",
   "metadata": {},
   "source": [
    "### Building a data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca468bb1",
   "metadata": {},
   "source": [
    "><font size=3>Ok, so we have a path to a data file. <font color='darkcyan'>So can we make a producer using this path?</font> No, openseize is a highly extensible package that will support many  different file types. Each of these file types will need to be read according to its own protocol. For reading EDF files, openseize has an EDF reader that reads... well EDF files. We discuss file readers in the file_reading demo. For now, we will make the EDF reader and explain the steps as we go along.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfe8edd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Reader in module openseize.io.edf:\n",
      "\n",
      "class Reader(openseize.io.bases.Reader)\n",
      " |  Reader(path)\n",
      " |  \n",
      " |  A reader of European Data Format (EDF/EDF+) files.\n",
      " |  \n",
      " |  The EDF specification has a header section followed by data records\n",
      " |  Each data record contains all signals stored sequentially. EDF+\n",
      " |  files include an annotation signal within each data record. To\n",
      " |  distinguish these signals we refer to data containing signals as\n",
      " |  channels and annotation signals as annotation. Currently, this reader\n",
      " |  does not support the reading of annotation signals.\n",
      " |  \n",
      " |  For details on the EDF/+ file specification please see:\n",
      " |  \n",
      " |  https://www.edfplus.info/specs/index.html\n",
      " |  \n",
      " |  Attributes:\n",
      " |      header: A dictionary representation of an EDF Header.\n",
      " |      shape: A tuple of channels, samples contained in this EDF\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Reader\n",
      " |      openseize.io.bases.Reader\n",
      " |      abc.ABC\n",
      " |      openseize.core.mixins.ViewInstance\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, path)\n",
      " |      Extends the Reader ABC with a header attribute.\n",
      " |  \n",
      " |  read(self, start, stop=None, channels=None, padvalue=nan)\n",
      " |      Reads samples from this EDF for the specified channels.\n",
      " |      \n",
      " |      Args:\n",
      " |          start: int\n",
      " |              The start sample index to read.\n",
      " |          stop: int\n",
      " |              The stop sample index to read (exclusive). If None, samples\n",
      " |              will be read until the end of file. Default is None.\n",
      " |          channels: sequence\n",
      " |              Sequence of channels to read from EDF. If None, all channels\n",
      " |              in the EDF will be read. Default is None.\n",
      " |          padvalue: float\n",
      " |              Value to pad to channels that run out of samples to return.\n",
      " |              Only applicable if sample rates of channels differ. Default\n",
      " |              padvalue is NaN.\n",
      " |      \n",
      " |      Returns: \n",
      " |          A float64 array of shape len(chs) x (stop-start) samples.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  shape\n",
      " |      Returns a 2-tuple containing the number of channels and \n",
      " |      number of samples in this EDF.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.io.bases.Reader:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |      Return reader instance as target variable of this context.\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_value, traceback)\n",
      " |      On context exit, close this reader's file object and propogate\n",
      " |      errors by returning None.\n",
      " |  \n",
      " |  close(self)\n",
      " |      Close this reader instance's opened file object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from openseize.io.bases.Reader:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from openseize.core.mixins.ViewInstance:\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Returns the __init__'s signature as the echo representation.\n",
      " |      \n",
      " |      Returns: str\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Returns this instances print representation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# how do  we build an edf reader -- ask for help!\n",
    "help(edf.Reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40c71a0",
   "metadata": {},
   "source": [
    "><font size=3>Under the methods section we see that to make a reader all we need is an edf path.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ded6b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the reader using the recording path we fetched\n",
    "reader = edf.Reader(recording_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890cc5ed",
   "metadata": {},
   "source": [
    "><font size=3>Also notice under the methods there is just one method called *read*. It reads samples from the EDF file between start and stop sample indices for each channel in channels list. Lets see if this does something.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4eb9aaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-19.87908032   7.95793213  19.88808032  18.89390131  18.89390131\n",
      "   43.74837671   6.96375311  30.8240495    5.9695741   22.87061737]\n",
      " [-86.4890744   51.70180884  63.63195703  88.48643243  63.63195703\n",
      "   61.643599    54.68434589  43.74837671  55.6785249   64.62613605]\n",
      " [-85.49489539  44.74255573  29.82987048  79.53882129  52.69598785\n",
      "   42.75419769  42.75419769  21.87643835  60.64941998  66.61449408]\n",
      " [ 62.63777802  95.44568555  77.55046326  36.7891236  109.36419177\n",
      "  118.31180292 122.28851898 115.32926587  76.55628424  44.74255573]]\n"
     ]
    }
   ],
   "source": [
    "values = reader.read(start=0, stop=10) #channels unspecified means read all channels\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111530f5",
   "metadata": {},
   "source": [
    "><font size=3>So we got an array of shape (4,10) back. <font color='darkcyan'>***Is that right?***</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "161efa7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reader Object\n",
      "---Attributes & Properties---\n",
      "{'path': PosixPath('/home/matt/python/nri/openseize/demos/data/recording_001.edf'),\n",
      " 'header': {'version': '0',\n",
      "            'patient': 'PIN-42 M 11-MAR-1952 Animal',\n",
      "            'recording': 'Startdate 15-AUG-2020 X X X',\n",
      "            'start_date': '15.08.20',\n",
      "            'start_time': '09.59.15',\n",
      "            'header_bytes': 1536,\n",
      "            'reserved_0': 'EDF+C',\n",
      "            'num_records': 3775,\n",
      "            'record_duration': 1.0,\n",
      "            'num_signals': 5,\n",
      "            'names': ['EEG EEG_1_SA-B', 'EEG EEG_2_SA-B', 'EEG EEG_3_SA-B',\n",
      "                      'EEG EEG_4_SA-B', 'EDF Annotations'],\n",
      "            'transducers': ['8401 HS:15279', '8401 HS:15279', '8401 HS:15279',\n",
      "                            '8401 HS:15279', ''],\n",
      "            'physical_dim': ['uV', 'uV', 'uV', 'uV', ''],\n",
      "            'physical_min': [-8144.31, -8144.31, -8144.31, -8144.31, -1.0],\n",
      "            'physical_max': [8144.319, 8144.319, 8144.319, 8144.319, 1.0],\n",
      "            'digital_min': [-8192.0, -8192.0, -8192.0, -8192.0, -32768.0],\n",
      "            'digital_max': [8192.0, 8192.0, 8192.0, 8192.0, 32767.0],\n",
      "            'prefiltering': ['none', 'none', 'none', 'none', ''],\n",
      "            'samples_per_record': [5000, 5000, 5000, 5000, 1024],\n",
      "            'reserved_1': ['', '', '', '', '']},\n",
      " 'shape': (4, 18875000)}\n",
      "\n",
      "Type help(Reader) for full documentation\n"
     ]
    }
   ],
   "source": [
    "# examine the reader with print\n",
    "print(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6b7ef5",
   "metadata": {},
   "source": [
    "><font size=3>Awesome! printing the reader gives us the EDFs header which tells us everything we need to know. The file contains 4 channels named [EEG EEG_1_SA-B,... EEG EEG_4_SA-B]. So our array shape makes sense</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224c206",
   "metadata": {},
   "source": [
    "><font size=3><font color='darkcyan'>**Can we finally build a producer? YES**</font>, producers can produce from any reader type as long as the reader has a method called <font color='firebrick'>**read**</font>. Lucky for us the EDF reader we just built has a read method</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd031d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
